{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitObjectDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZfnWC_NF7NM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch \n",
        "from torch import nn, optim \n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import itertools\n",
        "import glob \n",
        "from PIL import Image\n",
        "import csv \n",
        "import cv2\n",
        "import re\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision.ops.boxes import box_iou\n",
        "import random\n",
        "import torchvision\n",
        "import warnings\n",
        "\n",
        "!pip install --upgrade albumentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2, ToTensor\n",
        "!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
        "%cd Ranger-Deep-Learning-Optimizer\n",
        "!pip install -e .\n",
        "from ranger import Ranger  \n",
        "%cd ..\n",
        "#https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1\n",
        "!git clone https://github.com/davda54/sam.git\n",
        "%cd sam\n",
        "import sam\n",
        "print(\"Imported SAM Successfully from github .py file\")\n",
        "%cd ..\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_pckeYPGF0b",
        "outputId": "ee7d8f17-cbac-4ec2-e046-94b4c1ce908d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCS2doQYbNpf"
      },
      "source": [
        "## To Do Right Now: \n",
        "\n",
        "### Steps for fully integrating effecient det \n",
        "* Try to understand why eff det is failing. Maybe visualize images to see if bouding boxes are correct. \n",
        "* Also change the len(eff_train_dataset) and test \n",
        "\n",
        "### Think of Project Ideas\n",
        "\n",
        "### Labeling the other data on peaches. label them and put them in dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Goal \n",
        "Get model running on web cam on like 10 different fruits / vegetables\n",
        "\n",
        "#Less Urgent Ideas in the Future:\n",
        "\n",
        "### Idea for Increased functionality: Make code that counts fruits and fruits with bad_spots. For every fruit bounding box group fruit into no badspot, 2-4 (little amount of small badspots), big glob, huge amount of bad spots etc). \n",
        "\n",
        "### This will be in end when all my modeling, data collecting, and experimenting is done. Look into turning jupyter notebook into python script or deploy it to rasberry pi. Makes sure when converting to python script be aware of classes variable.\n",
        "\n",
        " \n",
        "### https://www.emerginginvestigators.org/articles?category_id=10\n",
        "\n",
        "### Train, Once I get a model with very good results. torch.save it state_dicts on my local disk. Also record results of models on results spreadsheet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UKDVNnIqQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42b68a2-b616-4de8-ad98-b713f897d5c6"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/LatestFruit Defects Dataset .zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/EfficientDet.Pytorch-Updated.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/noisy_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "%cd EfficientDet.Pytorch-Updated/\n",
        "import math\n",
        "from models.efficientnet import EfficientNet\n",
        "from models.bifpn import BIFPN\n",
        "from models.retinahead import RetinaHead\n",
        "from models.module import RegressionModel, ClassificationModel, Anchors, ClipBoxes, BBoxTransform\n",
        "from torchvision.ops import nms\n",
        "from models.losses import FocalLoss\n",
        "from models.efficientdet import EfficientDet\n",
        "from models.losses import FocalLoss\n",
        "from datasets import VOCDetection, CocoDataset, get_augumentation, detection_collate, Resizer, Normalizer, Augmenter, collater\n",
        "from utils import EFFICIENTDET, get_state_dict\n",
        "from eval import evaluate, evaluate_coco\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/EfficientDet.Pytorch-Updated\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY83cUEFAjoW",
        "outputId": "c22208f6-1fff-4e9c-c128-28078e2a6a4c"
      },
      "source": [
        "#For one strawberry batch please drop watermark rows\n",
        "strawberry_csv_batch_3 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/FreshStrawberries/Fresh StrawBerry Batch 3 Labeled/FreshStrawberryBatch3Labels.csv\", header = None)\n",
        "strawberry_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/FreshStrawberries/Fresh StrawBerry Batch 2 Labeled/FreshStrawberriesBatch2Labels.csv\", header = None)\n",
        "strawberry_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/FreshStrawberries/Fresh StrawBerry Batch 1 Labeled/Strawberrybatch1.csv\", header = None)\n",
        "rottenApple_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenApples/RottenAppleBatch1Labeled/RottenAppleBatch1Labels.csv\", header = None)\n",
        "rottenApple_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenApples/RottenAppleBatch2Labeled/RottenApplesBatch2Labels.csv\", header = None)\n",
        "rottenApple_csv_batch_3 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenApples/RottenAppleBatch3Labaled/RottenApplesBatch3Labels.csv\", header = None)\n",
        "rottenStrawberry_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenStrawberries/Batch1RottenStrawBerryLabels/RottenStrawberriesBatch1Labels.csv\", header = None)\n",
        "rottenStrawberry_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenStrawberries/Batch2RottenStrawBerryLabels/RottenStrawBerryBatch2.csv\", header = None)\n",
        "rottenStrawberry_csv_batch_3 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/RottenStrawberries/Batch3RottenStrawberrylabel/rottenStrawberryBtch3labels.csv\", header = None)\n",
        "freshApples_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/FreshApples/FreshApplebtch2label/FreshApplesBatch2LabelsFresh.csv\", header = None)\n",
        "freshApples_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/FreshApples/FreshApplesBatch1Labels/FreshAppleBatch1Labels.csv\", header = None)\n",
        "rottenTomato_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Rotten Tomatoes/Rotten TomatoBatch1/Batch1TomoatosLabelsBbox.csv\", header = None)\n",
        "rottenTomato_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Rotten Tomatoes/RottnTomatoBatch2/RottenTomatyoBatch2Labelss.csv\", header = None)\n",
        "rottenTomato_csv_batch_3 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Rotten Tomatoes/RottenTomatBtch3/RottenTomatoesBatch3Labssles.csv\", header = None)\n",
        "rottenTomato_csv_batch_4 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Rotten Tomatoes/RottenTomatoesBatch4/Tomatobatch4labelssRotten.csv\", header = None)\n",
        "freshTomato_csv_batch_1 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Fresh Tomatoes/FreshTomatoesBatch1Labelss/FreshTomatoesLabelsBatch1Labels.csv\", header = None)\n",
        "freshTomato_csv_batch_2 = pd.read_csv(\"/content/Fruit Defects Dataset /Train/Fresh Tomatoes/FreshTomatBatch2Labessls/Batch2TomatlabelsFresh.csv\", header = None)\n",
        "\n",
        "strawberry_csv_batch_3.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "strawberry_csv_batch_2.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "strawberry_csv_batch_1.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenApple_csv_batch_1.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenApple_csv_batch_2.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenApple_csv_batch_3.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenStrawberry_csv_batch_1.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenStrawberry_csv_batch_2.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenStrawberry_csv_batch_3.columns = [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "freshApples_csv_batch_2.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "freshApples_csv_batch_1.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenTomato_csv_batch_1.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenTomato_csv_batch_2.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenTomato_csv_batch_3.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "rottenTomato_csv_batch_4.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "freshTomato_csv_batch_1.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "freshTomato_csv_batch_2.columns =  [\"Fruit\", \"Coord1\", \"Coord2\", \"Coord3\", \"Coord4\", \"Image_id\", \"OneSize\", \"TwoSize\"]\n",
        "\n",
        "#Drop some watermark data for Fresh StrawBerry Batch 1 Labeled images [59, 9, 93]\n",
        "\n",
        "# strawberry_csv_batch_1 = strawberry_csv_batch_1[Image_id not in [\"FreshStrawberries59.jpeg, FreshStrawberries9.jpeg, FreshStrawberries93.jpeg\"]]\n",
        "strawberry_csv_batch_1.drop(strawberry_csv_batch_1[strawberry_csv_batch_1[\"Image_id\"] == \"FreshStrawberries59.jpeg\"].index, inplace = True)\n",
        "strawberry_csv_batch_1.drop(strawberry_csv_batch_1[strawberry_csv_batch_1[\"Image_id\"] == \"FreshStrawberries9.jpeg\"].index, inplace = True)\n",
        "strawberry_csv_batch_1.drop(strawberry_csv_batch_1[strawberry_csv_batch_1[\"Image_id\"] == \"FreshStrawberries93.jpeg\"].index, inplace = True)\n",
        "freshTomato_csv_batch_1.drop(freshTomato_csv_batch_1[freshTomato_csv_batch_1[\"Image_id\"] == \"Fresh Tomatoes66AddonPart1.jpeg\"].index, inplace = True)\n",
        "\n",
        "strawberry_csv_batch_1 = strawberry_csv_batch_1.reset_index(drop=True)\n",
        "freshTomato_csv_batch_1 = freshTomato_csv_batch_1.reset_index(drop = True)\n",
        "\n",
        "#Stack all the csv files together. \n",
        "list_of_all_dataframes = [strawberry_csv_batch_1, strawberry_csv_batch_2, strawberry_csv_batch_3, rottenApple_csv_batch_1, \n",
        "                          rottenApple_csv_batch_2, rottenApple_csv_batch_3, rottenStrawberry_csv_batch_1, rottenStrawberry_csv_batch_2, \n",
        "                          rottenStrawberry_csv_batch_3, freshApples_csv_batch_2, freshApples_csv_batch_1, rottenTomato_csv_batch_1, \n",
        "                          rottenTomato_csv_batch_2, rottenTomato_csv_batch_3, rottenTomato_csv_batch_4, freshTomato_csv_batch_1, \n",
        "                          freshTomato_csv_batch_2]\n",
        "fruit_df = pd.concat(list_of_all_dataframes, ignore_index = True)\n",
        "\n",
        "total_row_sum_check = 0 \n",
        "for dataframe in list_of_all_dataframes:\n",
        "  total_row_sum_check += dataframe.shape[0]\n",
        "print(\"Checked total rows from all the dataframes combined: {}\".format(total_row_sum_check))\n",
        "\n",
        "def run_dataframe_check():\n",
        "  assert total_row_sum_check == fruit_df.shape[0]\n",
        "  print(\"DataFrame shape: {}\".format(fruit_df.shape))\n",
        "  print(\"Unique Fruit Labels {}\".format(fruit_df[\"Fruit\"].unique()))\n",
        "  print(\"Number of Unique Images {}\".format(len(fruit_df[\"Image_id\"].unique())))\n",
        "\n",
        "run_dataframe_check()\n",
        "\n",
        "#Specify more image types when \n",
        "def more_specific_Image_id(image_id, fruit):\n",
        "  if fruit == \"Bad_Spots\":\n",
        "    if re.search(\"RottenStrawberries\", image_id):\n",
        "      return \"Strawberry_Bad_Spot\"\n",
        "    elif re.search(\"RottenApples\", image_id):\n",
        "      return \"Apple_Bad_Spot\"\n",
        "    elif re.search(\"Rotten Tomatoes\", image_id):\n",
        "      return \"Tomato_Bad_Spot\"\n",
        "    else:\n",
        "      raise ValueError(\"Could not find a match for some of the Image_ids\")\n",
        "\n",
        "  else:\n",
        "    return fruit\n",
        "\n",
        "fruit_df[\"Fruit\"] = fruit_df.apply(lambda row: more_specific_Image_id(row.Image_id, row.Fruit), axis = 1)\n",
        "\n",
        "run_dataframe_check()\n",
        "\n",
        "#Post Processing \n",
        "fruit_df = fruit_df[fruit_df[\"Image_id\"] != \"FreshStrawberries15.jpeg\"]\n",
        "\n",
        "bounding_box_dict = dict()\n",
        "labels_dict = dict()\n",
        "classes = [\"Placeholder\", \"Apples\", \"Strawberry\", \"Tomato\", \"Apple_Bad_Spot\", \"Strawberry_Bad_Spot\", \"Tomato_Bad_Spot\"]\n",
        "# classes = [\"Apples\", \"Strawberry\", \"Apple_Bad_Spot\", \"Strawberry_Bad_Spot\"]\n",
        "print(classes)\n",
        "# classes = [\"Bad_Spots\", \"Strawberry\", \"Apples\"]\n",
        "\n",
        "for row_index in range(len(fruit_df)): \n",
        "  current_image_file = fruit_df.iloc[row_index][\"Image_id\"]\n",
        "  if current_image_file not in bounding_box_dict:\n",
        "    bounding_box_dict[current_image_file] = list()\n",
        "    labels_dict[current_image_file] = list()\n",
        "  bounding_box_dict[current_image_file].append(fruit_df.iloc[row_index, 1:5].to_list())\n",
        "  labels_dict[current_image_file].append(classes.index(fruit_df.iloc[row_index, 0]))\n",
        "\n",
        "print(len(bounding_box_dict))\n",
        "print(len(labels_dict))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checked total rows from all the dataframes combined: 1882\n",
            "DataFrame shape: (1882, 8)\n",
            "Unique Fruit Labels ['Strawberry' 'Apples' 'Bad_Spots' 'Tomato']\n",
            "Number of Unique Images 532\n",
            "DataFrame shape: (1882, 8)\n",
            "Unique Fruit Labels ['Strawberry' 'Apples' 'Apple_Bad_Spot' 'Strawberry_Bad_Spot' 'Tomato'\n",
            " 'Tomato_Bad_Spot']\n",
            "Number of Unique Images 532\n",
            "['Placeholder', 'Apples', 'Strawberry', 'Tomato', 'Apple_Bad_Spot', 'Strawberry_Bad_Spot', 'Tomato_Bad_Spot']\n",
            "531\n",
            "531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15qhrCwGUPxp"
      },
      "source": [
        "## Class function + util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgVTPiupUTQa"
      },
      "source": [
        "def ffile_path(image_id, full_image_file_paths):\n",
        "  for image_path in full_image_file_paths:\n",
        "    if image_id in image_path:\n",
        "      return image_path\n",
        "\n",
        "def find_area_bb(bb_coord):\n",
        "  bb_coord = bb_coord.numpy()\n",
        "  area_of_each_bb = list()\n",
        "  for pair_of_coord in bb_coord:\n",
        "    area_of_each_bb.append(\n",
        "        (pair_of_coord[2] - pair_of_coord[0]) * (pair_of_coord[3] - pair_of_coord[1])\n",
        "    )\n",
        "  return torch.tensor(area_of_each_bb, dtype=torch.int32)\n",
        "\n",
        "def convert_min_max(bb_coord):\n",
        "  for pair_of_coord in bb_coord:\n",
        "    pair_of_coord[2], pair_of_coord[3] = (pair_of_coord[0] + pair_of_coord[-2]), (pair_of_coord[1] + pair_of_coord[-1])\n",
        "  return bb_coord\n",
        "\n",
        "class FruitDetectDataset(object):\n",
        "  def __init__(self, id_labels, id_bounding_boxes, transforms, mode, noisy_dataset_path = None):\n",
        "\n",
        "    assert len(id_labels) == len(id_bounding_boxes)\n",
        "    assert sorted(id_labels.keys()) == sorted(id_bounding_boxes.keys())\n",
        "    self.imgs_key = sorted(id_labels.keys())\n",
        "\n",
        "    if noisy_dataset_path:\n",
        "      self.noisy_fp = [fp for fp in glob.glob(os.path.join(noisy_dataset_path, \"*.JPEG\"))]\n",
        "      \n",
        "      print(\"Noisy Has been subsetted\")\n",
        "      #Go to this code if you want to subset.\n",
        "      self.noisy_fp = self.noisy_fp[:40]\n",
        "      \n",
        "    else:\n",
        "      print(\"Dataset getting configured without noise loader\")\n",
        "      self.noisy_fp = list()\n",
        "\n",
        "    # np.random.shuffle(self.imgs_key)\n",
        "    if (mode == \"train\"):\n",
        "      self.imgs_key = self.imgs_key[:int(len(self.imgs_key) * 0.8)]\n",
        "      if noisy_dataset_path:\n",
        "        print(\"Extended {} noisy images to train set\".format(int(len(self.noisy_fp) * 0.8)))\n",
        "        self.imgs_key.extend(self.noisy_fp[:int(len(self.noisy_fp) * 0.8)])\n",
        "    elif (mode == \"test\"):\n",
        "      self.imgs_key = self.imgs_key[int(len(self.imgs_key) * 0.8):]\n",
        "      if noisy_dataset_path:\n",
        "        print(\"Extended {} noisy images to test set\".format(int(len(self.noisy_fp) * 0.2)))\n",
        "        self.imgs_key.extend(self.noisy_fp[int(len(self.noisy_fp) * 0.8):])\n",
        "    else:\n",
        "      raise ValueError(\"Invalid Mode choose from train or test\")\n",
        "\n",
        "    self.id_labels = id_labels\n",
        "    self.id_bounding_boxes = id_bounding_boxes\n",
        "    self.full_image_file_paths = glob.glob(\"/content/Fruit Defects Dataset /Train/*/*/*.jpeg\")\n",
        "\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    img_key = self.imgs_key[idx]\n",
        "    if img_key in self.noisy_fp:\n",
        "      img_path = img_key\n",
        "      boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "      labels = torch.as_tensor([], dtype = torch.int64)\n",
        "    else:\n",
        "      img_path = ffile_path(self.imgs_key[idx], self.full_image_file_paths) \n",
        "      boxes = convert_min_max(torch.as_tensor(self.id_bounding_boxes[self.imgs_key[idx]], dtype=torch.float32))\n",
        "      labels = torch.as_tensor(self.id_labels[self.imgs_key[idx]], dtype=torch.int64)\n",
        "    \n",
        "    img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "    image_id = torch.tensor([idx])\n",
        "    area = find_area_bb(boxes)\n",
        "\n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = image_id\n",
        "    target[\"area\"] = area\n",
        "    \n",
        "    #Query about transforms for labels of images\n",
        "    if self.transforms: \n",
        "      sample = {\n",
        "                'image': img,\n",
        "                'bboxes': target['boxes'],\n",
        "                'labels': labels\n",
        "            }\n",
        "\n",
        "      sample = self.transforms(**sample)\n",
        "      img = sample['image']\n",
        "\n",
        "      if img_key not in self.noisy_fp:\n",
        "        target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
        "    \n",
        "    \n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs_key)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDh2_pg4J2yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26916bfa-a00a-4923-9cb3-bca9ebf5ffe0"
      },
      "source": [
        "\n",
        "#The Drawing function.\n",
        "# COLORS = [(255, 0, 0), (0, 255, 0), (0, 0 , 255), (255, 255, 0)]\n",
        "COLORS = [(0, 0, 0), (0, 255, 0), (0, 0 , 255), (255, 255, 0), (255, 0, 0)]\n",
        "\n",
        "def draw_boxes(boxes, labels, image, infer = False, put_text = True):\n",
        "    # read the image with OpenCV\n",
        "    image = image.permute(1, 2, 0).numpy()\n",
        "    if infer:\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    for i, box in enumerate(boxes):\n",
        "        color = COLORS[labels[i] % len(COLORS)]\n",
        "        cv2.rectangle(\n",
        "            image,\n",
        "            (int(box[0]), int(box[1])),\n",
        "            (int(box[2]), int(box[3])),\n",
        "            color, 2\n",
        "        )\n",
        "        if put_text:\n",
        "          cv2.putText(image, classes[labels[i]], (int(box[0]), int(box[1]-5)),\n",
        "                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, \n",
        "                      lineType=cv2.LINE_AA)\n",
        "    return image\n",
        "\n",
        "# Albumentations\n",
        "def get_transforms(mode):\n",
        "  if (mode == \"train\"):\n",
        "    return A.Compose([\n",
        "                      A.OneOf([\n",
        "                      A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
        "                                     val_shift_limit=0.2, p=0.9),\n",
        "                      A.RandomBrightnessContrast(brightness_limit=0.2, \n",
        "                                           contrast_limit=0.2, p=0.9)],p=0.9),\n",
        "                      A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),\n",
        "                      A.HorizontalFlip(),\n",
        "                      A.VerticalFlip(), \n",
        "                      # A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), p=1),\n",
        "                      # ToTensor(),\n",
        "                      ToTensorV2()\n",
        "                      ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "  elif (mode == \"test\"):\n",
        "    return A.Compose([\n",
        "                      # A.Resize(512, 512), \n",
        "                      # A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                      # std=(0.229, 0.224, 0.225), p=1),\n",
        "                      # ToTensor()\n",
        "                      ToTensorV2()\n",
        "                      ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "  elif (mode == \"effdet_train\"):\n",
        "    return A.Compose([\n",
        "                      A.OneOf([\n",
        "                      A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
        "                                     val_shift_limit=0.2, p=0.9),\n",
        "                      A.RandomBrightnessContrast(brightness_limit=0.2, \n",
        "                                           contrast_limit=0.2, p=0.9)],p=0.9),\n",
        "                      A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),\n",
        "                      A.HorizontalFlip(),\n",
        "                      A.VerticalFlip(), \n",
        "                      A.Resize(height = 512, width=512), \n",
        "                      ToTensorV2()\n",
        "                      ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "  elif (mode == \"effdet_test\"):\n",
        "    return A.Compose([\n",
        "                      A.Resize(height = 512, width = 512), \n",
        "                      ToTensorV2()])\n",
        "  else:\n",
        "    raise ValueError(\"mode is wrong value can either be train or test\")\n",
        "\n",
        "class NoiseDataset(object):\n",
        "\n",
        "  def __init__(self, noise_file_path, size, camera_size):\n",
        "\n",
        "    self.size = size\n",
        "    self.noise_file_path = [fp for fp in glob.glob(os.path.join(noise_file_path, \"*.JPEG\"))]\n",
        "    self.transforms = transforms.Compose([\n",
        "                                          transforms.Resize((camera_size, camera_size)), \n",
        "                                          transforms.ToTensor()])\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    current_file_path = self.noise_file_path[idx]\n",
        "    img = Image.open(current_file_path).convert(\"RGB\")\n",
        "\n",
        "    img = self.transforms(img)\n",
        "    return img\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.size:\n",
        "      return self.size\n",
        "    return len(self.noise_file_path)\n",
        "    \n",
        "\n",
        "#Using this stack overflow (https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders)\n",
        "#(Suppose for example, you want to create batches of a list of varying dimension tensors. The below code pads sequences with 0 until the maximum sequence size of the batch,)\n",
        "#Collate_fn is a function that is used to process your batches before you pass it to dataloader. In my case since I have different sized images I need a way to stack batches b/c torch.stack won't work.\n",
        "#So I use zip which can accept tensors of different lengths and make them stacked with the size of the lowest length list given. Therefore stacking all the images in a batch \n",
        "#Successfully unlike torch.stack and doing that processing to every batch makes collate_fn vital since I have different image sizes.\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return tuple([list(a) for a in zip(*batch)])\n",
        "    # return tuple(zip(*batch))\n",
        "\n",
        "train_batch_size = 2\n",
        "test_batch_size = 2\n",
        "noise_path = \"/content/noisy_dataset\"\n",
        "\n",
        "train_dataset = FruitDetectDataset(labels_dict, bounding_box_dict, get_transforms(mode = \"train\"), mode = \"train\", noisy_dataset_path=noise_path)                               \n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True, collate_fn= collate_fn)\n",
        "\n",
        "test_dataset = FruitDetectDataset(labels_dict, bounding_box_dict, get_transforms(mode = \"test\"), mode = \"test\", noisy_dataset_path=noise_path)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = test_batch_size, shuffle = True, collate_fn= collate_fn)\n",
        "\n",
        "noise_dataset = NoiseDataset(noise_path, 100, 512)\n",
        "noise_loader = torch.utils.data.DataLoader(noise_dataset, batch_size = test_batch_size, shuffle = True)\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noisy Has been subsetted\n",
            "Extended 32 noisy images to train set\n",
            "Noisy Has been subsetted\n",
            "Extended 8 noisy images to test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "-uf9fdpPK-SQ",
        "outputId": "56aba840-828b-4687-a625-1d4d840cdf1d"
      },
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(2):\n",
        "    ax = fig.add_subplot(2, 2/2, idx+1, xticks=[], yticks=[])\n",
        "    image = draw_boxes(labels[idx][\"boxes\"], labels[idx][\"labels\"], images[idx])\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A0EkOWcPSX0"
      },
      "source": [
        "## What we learned\n",
        "is that the model outputs losses when in train mode \n",
        "when in model.eval model, the model code then return only a prediction with no losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NQrBD22VWxD"
      },
      "source": [
        "def calculate_metrics(target_box,predictions_box,scores, device):\n",
        "\n",
        "    #Get most confident boxes first and least confident last\n",
        "    predictions_box = predictions_box[scores.argsort().flip(-1)]\n",
        "    iou_mat = box_iou(target_box,predictions_box)\n",
        "    #return a one by one matrix that is form (target_box, prediction_box) or (1, 1)\n",
        "    target_boxes_count, prediction_boxes_count = iou_mat.shape\n",
        "    \n",
        "    mAP_Matrix = torch.zeros_like(iou_mat)\n",
        "    # if not matrix coordinates that relate to nothing.\n",
        "    if not iou_mat[:,0].eq(0.).all():\n",
        "      index_of_biggest_iou = iou_mat[:,0].argsort()[-1]\n",
        "      mAP_Matrix[index_of_biggest_iou,0] = 1\n",
        "\n",
        "    for pr_idx in range(1,prediction_boxes_count):\n",
        "        not_assigned = torch.logical_not(mAP_Matrix[:,:pr_idx].sum(1)).long()\n",
        "        targets = not_assigned * iou_mat[:,pr_idx]\n",
        "\n",
        "        if targets.eq(0).all():\n",
        "            continue\n",
        "\n",
        "        pivot = targets.argsort()[-1]\n",
        "        mAP_Matrix[pivot,pr_idx] = 1\n",
        "\n",
        "    # mAP calculation\n",
        "    tp = mAP_Matrix.sum()\n",
        "    fp = mAP_Matrix.sum(0).eq(0).sum()\n",
        "    fn = mAP_Matrix.sum(1).eq(0).sum()\n",
        "\n",
        "    mAP = tp / (tp+fp)\n",
        "    mAR = tp / (tp+fn)\n",
        "\n",
        "    return mAP, mAR\n",
        "\n",
        "def run_metrics_for_batch(output, targets, mAP, mAR, missed_images, device):\n",
        "  for pos_in_batch, image_pred in enumerate(output):\n",
        "    assert (len(image_pred[\"boxes\"]) == len(image_pred[\"labels\"]) == len(image_pred[\"scores\"]))\n",
        "    if len(image_pred[\"boxes\"]) != 0:\n",
        "      curr_mAP, curr_mAR = calculate_metrics(targets[pos_in_batch][\"boxes\"], output[pos_in_batch][\"boxes\"], output[pos_in_batch][\"scores\"], device)\n",
        "      mAP, mAR = mAP + curr_mAP , mAR + curr_mAR\n",
        "    else:\n",
        "      missed_images += 1 \n",
        "  \n",
        "  return mAP, mAR, missed_images\n",
        "\n",
        "def run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, mAP, mAR, missed_images, device):\n",
        "    assert (len(scores) == len(classification) == len(transformed_anchors))\n",
        "    if len(transformed_anchors) != 0:\n",
        "      curr_mAP, curr_mAR = calculate_metrics(targets[0][:, :4], transformed_anchors, scores, device)\n",
        "      mAP, mAR = mAP + curr_mAP , mAR + curr_mAR\n",
        "    else:\n",
        "      missed_images += 1 \n",
        "      \n",
        "    return mAP, mAR, missed_images\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnukB06TZqTb"
      },
      "source": [
        "https://pypi.org/project/pytorch-warmup/ link for doing warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB_w3zeIOa8X"
      },
      "source": [
        "def train(net, epochs, train_loader, test_loader, noise_loader, lr, weight_decay, \n",
        "          print_every = 6, lo_test_dataset = len(test_dataset), lo_train_dataset = len(train_dataset),\n",
        "          lo_noise_dataset = len(noise_dataset)):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #Check which parameters can calculate gradients. \n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "\n",
        "    # optimizer = Ranger(net.parameters(), lr = lr, weight_decay= weight_decay)\n",
        "    base_optimizer = Ranger\n",
        "    optimizer = sam.SAM(net.parameters(), base_optimizer, lr = lr, weight_decay = weight_decay)\n",
        "    \n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
        "\n",
        "    net.to(device)\n",
        "    print(\"Device: {}\".format(device))\n",
        "    print(\"Optimizer: {}\".format(optimizer))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        \n",
        "        train_loss = steps = train_mAP = train_mAR = missed_train_images = 0\n",
        "        \n",
        "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "            net.train()\n",
        "\n",
        "            steps += 1\n",
        "            \n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_dict = net(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            net.eval()\n",
        "            train_mAP, train_mAR, missed_train_images = run_metrics_for_batch(net(images), targets, train_mAP, train_mAR, missed_train_images, device)\n",
        "            net.train()\n",
        "\n",
        "            losses.backward()\n",
        "            # optimizer.step()\n",
        "\n",
        "            optimizer.first_step(zero_grad = True)\n",
        "\n",
        "            loss_dict = net(images, targets)\n",
        "\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            losses.backward()\n",
        "            optimizer.second_step(zero_grad = True)\n",
        "\n",
        "            train_loss +=  losses.item()\n",
        "            scheduler.step()\n",
        "\n",
        "            if (steps % print_every) == 0:\n",
        "\n",
        "              with torch.no_grad():\n",
        "                test_mAP = test_mAR = missed_test_images = test_loss = correct_missed_images = 0\n",
        "\n",
        "                for noise_images in noise_loader:\n",
        "                  \n",
        "                  net.eval()\n",
        "                  if device == torch.device(\"cuda\"):\n",
        "                    noise_images = [noise_image.to(device) for noise_image in noise_images]\n",
        "                  \n",
        "                  output = net(noise_images)\n",
        "\n",
        "                  for ii in range(len(output)):\n",
        "                    if len(output[ii][\"boxes\"]) == 0:\n",
        "                      correct_missed_images += 1\n",
        "\n",
        "                for images, targets in test_loader:\n",
        "\n",
        "                  net.eval()\n",
        "                  if device == torch.device(\"cuda\"):\n",
        "                    images = [image.to(device) for image in images]\n",
        "                    targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
        "\n",
        "                  output = net(images)\n",
        "                  test_mAP, test_mAR, missed_test_images = run_metrics_for_batch(output, targets, test_mAP, test_mAR, missed_test_images, device)\n",
        "\n",
        "                  net.train()\n",
        "                  test_loss_dict = net(images, targets)\n",
        "                  test_losses = sum(loss for loss in test_loss_dict.values())\n",
        "                  test_loss += test_losses.item()\n",
        "\n",
        "                for param_group in optimizer.param_groups:\n",
        "                  learning_rate_extract = param_group[\"lr\"]\n",
        "                print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Test_loss: {:0.2f} | Test mAP: {:0.2f}% | Missed Test Images: {} | Seperate Noise Loader: {} / {}\".format(\n",
        "                    epoch + 1, epochs, steps, learning_rate_extract, train_loss, test_loss,  \n",
        "                    (test_mAP / float(lo_test_dataset)) * 100.,missed_test_images,\n",
        "                    correct_missed_images, lo_noise_dataset))\n",
        "\n",
        "              assert (steps % print_every) == 0\n",
        "              train_loss = 0\n",
        "                 \n",
        "        print(\"\\n Epoch {} Final Train mAP: {:0.2f}% | Epoch {} Final Missed Train Images: {} out of {} images \\n\".format(\n",
        "            epoch + 1, (train_mAP / float(lo_train_dataset)) * 100., \n",
        "            epoch + 1, missed_train_images, lo_train_dataset\n",
        "        ))\n",
        "    \n",
        "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYAu4FDknTwH"
      },
      "source": [
        "# Effecient Det Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HjFx0ZuYFca"
      },
      "source": [
        "class EffdetFruitDetectDataset(object):\n",
        "  def __init__(self, id_labels, id_bounding_boxes, transforms, mode):\n",
        "\n",
        "    assert len(id_labels) == len(id_bounding_boxes)\n",
        "    assert sorted(id_labels.keys()) == sorted(id_bounding_boxes.keys())\n",
        "    self.imgs_key = sorted(id_labels.keys())\n",
        "\n",
        "    np.random.shuffle(self.imgs_key)\n",
        "    if (mode == \"train\"):\n",
        "      self.imgs_key = self.imgs_key[:int(len(self.imgs_key) * 0.8)]\n",
        "    else:\n",
        "      self.imgs_key = self.imgs_key[int(len(self.imgs_key) * 0.8):]\n",
        "\n",
        "    self.id_labels = id_labels\n",
        "    self.id_bounding_boxes = id_bounding_boxes\n",
        "    self.full_image_file_paths = glob.glob(\"/content/Fruit Defects Dataset /Train/*/*/*.jpeg\")\n",
        "\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    img_path = ffile_path(self.imgs_key[idx], self.full_image_file_paths) \n",
        "    img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "    boxes = convert_min_max(torch.as_tensor(self.id_bounding_boxes[self.imgs_key[idx]], dtype=torch.float32))\n",
        "    \n",
        "    labels = torch.as_tensor(self.id_labels[self.imgs_key[idx]], dtype=torch.int64)\n",
        "    \n",
        "    #Query about transforms for labels of images\n",
        "    if self.transforms: \n",
        "      sample = {\n",
        "                'image': img,\n",
        "                'bboxes': boxes,\n",
        "                'labels': labels\n",
        "            }\n",
        "\n",
        "      sample = self.transforms(**sample)\n",
        "      img = sample['image']\n",
        "      boxes = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
        "\n",
        "    return {'image': img, 'bboxes': boxes, 'category_id': labels}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs_key)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmonKCf2YtY2"
      },
      "source": [
        "def detection_collate(batch):\n",
        "    imgs = [s['image'] for s in batch]\n",
        "    annots = [s['bboxes'] for s in batch]\n",
        "    labels = [s['category_id'] for s in batch]\n",
        "\n",
        "    max_num_annots = max(len(annot) for annot in annots)\n",
        "    annot_padded = np.ones((len(annots), max_num_annots, 5))*-1\n",
        "\n",
        "    if max_num_annots > 0:\n",
        "        for idx, (annot, lab) in enumerate(zip(annots, labels)):\n",
        "            if len(annot) > 0:\n",
        "                annot_padded[idx, :len(annot), :4] = annot\n",
        "                annot_padded[idx, :len(annot), 4] = lab\n",
        "    return (torch.stack(imgs, 0), torch.FloatTensor(annot_padded))\n",
        "\n",
        "train_batch_size = 1\n",
        "valid_batch_size = 1\n",
        "\n",
        "eff_train_dataset = EffdetFruitDetectDataset(labels_dict, bounding_box_dict, get_transforms(mode = \"effdet_train\"), mode = \"train\")\n",
        "eff_train_loader = torch.utils.data.DataLoader(eff_train_dataset, batch_size = train_batch_size, shuffle = True, collate_fn= detection_collate)\n",
        "\n",
        "eff_test_dataset = EffdetFruitDetectDataset(labels_dict, bounding_box_dict, get_transforms(mode = \"effdet_test\"), mode = \"test\")\n",
        "eff_test_loader = torch.utils.data.DataLoader(eff_test_dataset, batch_size = valid_batch_size, shuffle = True, collate_fn = detection_collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF1AnUSZienq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70505545-f831-4b73-e51b-4a8e0165d18d"
      },
      "source": [
        "MODEL_MAP = {\n",
        "    'efficientdet-d0': 'efficientnet-b0',\n",
        "    'efficientdet-d1': 'efficientnet-b1',\n",
        "    'efficientdet-d2': 'efficientnet-b2',\n",
        "    'efficientdet-d3': 'efficientnet-b3',\n",
        "    'efficientdet-d4': 'efficientnet-b4',\n",
        "    'efficientdet-d5': 'efficientnet-b5',\n",
        "    'efficientdet-d6': 'efficientnet-b6',\n",
        "    'efficientdet-d7': 'efficientnet-b6',\n",
        "}\n",
        "class EfficientDet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 network='efficientdet-d0',\n",
        "                 D_bifpn=3,\n",
        "                 W_bifpn=88,\n",
        "                 D_class=3,\n",
        "                 is_training=True,\n",
        "                 threshold=0.001, #can change this value 0.01\n",
        "                 iou_threshold=1): # can change this value 0.5\n",
        "        super(EfficientDet, self).__init__()\n",
        "        \n",
        "        self.backbone = EfficientNet.from_pretrained(MODEL_MAP[network])\n",
        "        self.is_training = is_training\n",
        "        self.neck = BIFPN(in_channels=self.backbone.get_list_features()[-5:],\n",
        "                          out_channels=W_bifpn,\n",
        "                          stack=D_bifpn,\n",
        "                          num_outs=5)\n",
        "        self.bbox_head = RetinaHead(num_classes=num_classes,\n",
        "                                    in_channels=W_bifpn)\n",
        "\n",
        "        self.anchors = Anchors()\n",
        "        self.regressBoxes = BBoxTransform()\n",
        "        self.clipBoxes = ClipBoxes()\n",
        "        self.threshold = threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "        self.freeze_bn()\n",
        "        self.criterion = FocalLoss()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.is_training:\n",
        "            inputs, annotations = inputs\n",
        "        else:\n",
        "            inputs = inputs\n",
        "        x = self.extract_feat(inputs)\n",
        "        outs = self.bbox_head(x)\n",
        "        classification = torch.cat([out for out in outs[0]], dim=1)\n",
        "        regression = torch.cat([out for out in outs[1]], dim=1)\n",
        "        anchors = self.anchors(inputs)\n",
        "        if self.is_training:\n",
        "            return self.criterion(classification, regression, anchors, annotations)\n",
        "        else:\n",
        "            transformed_anchors = self.regressBoxes(anchors, regression)\n",
        "            transformed_anchors = self.clipBoxes(transformed_anchors, inputs)\n",
        "            scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
        "            scores_over_thresh = (scores > self.threshold)[0, :, 0]\n",
        "\n",
        "            if scores_over_thresh.sum() == 0:\n",
        "                # print('No boxes to NMS')\n",
        "                # no boxes to NMS, just return\n",
        "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\n",
        "            classification = classification[:, scores_over_thresh, :]\n",
        "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\n",
        "            scores = scores[:, scores_over_thresh, :]\n",
        "            anchors_nms_idx = nms(\n",
        "                transformed_anchors[0, :, :], scores[0, :, 0], iou_threshold=self.iou_threshold)\n",
        "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(\n",
        "                dim=1)\n",
        "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\n",
        "\n",
        "    def freeze_bn(self):\n",
        "        '''Freeze BatchNorm layers.'''\n",
        "        for layer in self.modules():\n",
        "            if isinstance(layer, nn.BatchNorm2d):\n",
        "                layer.eval()\n",
        "\n",
        "    def extract_feat(self, img):\n",
        "        \"\"\"\n",
        "            Directly extract features from the backbone+neck\n",
        "        \"\"\"\n",
        "        x = self.backbone(img)\n",
        "        x = self.neck(x[-5:])\n",
        "        return x\n",
        "\n",
        "model= EfficientDet(num_classes=len(classes),is_training=True)\n",
        "model.train()\n",
        "\n",
        "model.freeze_bn()\n",
        "\n",
        "model = model.cuda()\n",
        "print('Run with DataParallel ....')\n",
        "\n",
        "## Make sure that you add this line, even though you are not using more than one \n",
        "# GPU DataParallel adds \"module\" to the start of the model structure \n",
        "# allowing for the syntax to be correct when calling \"model.module.freeze_bn()\" for example\n",
        "model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "# I am doing this here an example, you do not have to call the lines below here\n",
        "model.module.is_training = True\n",
        "model.module.freeze_bn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "Run with DataParallel ....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS4fTCSYULYU"
      },
      "source": [
        "def train_effdet(net, epochs, train_loader, test_loader, lr, weight_decay, \n",
        "          print_every = 6, lo_test_dataset = len(eff_test_dataset), lo_train_dataset = len(eff_train_dataset)):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device: {}\".format(device))\n",
        "    print(\"Note: Train Accuracies are only run through one train image per batch\")\n",
        "\n",
        "    if device == torch.device(\"cpu\"):\n",
        "      warnings.warn(\"Code does not support running on CPU but only GPU\")\n",
        "\n",
        "    optimizer = optim.AdamW(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
        "\n",
        "    start_time = time.time()\n",
        "    net.module.freeze_bn()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        net.train()\n",
        "        net.module.is_training = True\n",
        "        \n",
        "        train_loss = steps = train_mAP = train_mAR = missed_train_images = 0\n",
        "        \n",
        "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "\n",
        "            net.train()\n",
        "            net.module.is_training = True\n",
        "\n",
        "            steps += 1\n",
        "            \n",
        "            images = images.cuda().float()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "            classification_loss, regression_loss = model([images, targets])\n",
        "            classification_loss = classification_loss.mean()\n",
        "            regression_loss = regression_loss.mean()\n",
        "            loss = classification_loss + regression_loss\n",
        "            if bool(loss == 0):\n",
        "              print('loss equal zero(0)')\n",
        "              continue\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            net.eval()\n",
        "            net.module.is_training = False\n",
        "            scores, classification, transformed_anchors = net(images[0].unsqueeze(0))\n",
        "            train_mAP, train_mAR, missed_train_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, train_mAP, \n",
        "                                                                                     train_mAR, missed_train_images, device)\n",
        "            net.train()\n",
        "            net.module.is_training = True\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            if (steps % print_every) == 0:\n",
        "\n",
        "              with torch.no_grad():\n",
        "                test_mAP = test_mAR = missed_test_images = test_loss = 0\n",
        "\n",
        "                for images, targets in test_loader:\n",
        "\n",
        "                  if images.size(0) != 1:\n",
        "                    warning.warn(\"Only can validate fully with batch size of 1, \\\n",
        "                    bigger batch sizes risk Errors or Incomplete Validation\")\n",
        "                  \n",
        "                  net.eval()\n",
        "                  net.module.is_training = False\n",
        "\n",
        "                  if device == torch.device(\"cuda\"):\n",
        "                    images = images.cuda().float()\n",
        "                    targets = targets.cuda()\n",
        "\n",
        "                  scores, classification, transformed_anchors = net(images)\n",
        "                  test_mAP, test_mAR, missed_test_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, \n",
        "                                                                                 test_mAP, test_mAR, missed_test_images, device)\n",
        "\n",
        "                  net.train()\n",
        "                  net.module.is_training = True\n",
        "\n",
        "                  classification_loss, regression_loss = model([images, targets])\n",
        "                  classification_loss = classification_loss.mean()\n",
        "                  regression_loss = regression_loss.mean()\n",
        "                  loss = classification_loss + regression_loss\n",
        "\n",
        "                  test_loss += loss.item()\n",
        "\n",
        "                for param_group in optimizer.param_groups:\n",
        "                  learning_rate_extract = param_group[\"lr\"]\n",
        "                print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Test_loss: {:0.2f} | Test mAP: {:0.2f}% | Test mAR: {:0.2f}% | Missed Test Images: {}\".format(\n",
        "                    epoch + 1, epochs, steps, learning_rate_extract, train_loss, test_loss,  \n",
        "                    (test_mAP / float(lo_test_dataset)) * 100., (test_mAR / float(lo_test_dataset)) * 100.,missed_test_images))\n",
        "\n",
        "              assert (steps % print_every) == 0\n",
        "              train_loss = 0\n",
        "              # scheduler.step(test_loss / float(lo_test_dataset))\n",
        "             \n",
        "        print(\"\\n Epoch {} Final Train mAP: {:0.2f}% | Epoch {} Final Train mAR: {:0.2f}% | Epoch {} Final Missed Train Images: {} out of {} images \\n\".format(\n",
        "            epoch + 1, (train_mAP / float(lo_train_dataset)) * 100., \n",
        "            epoch + 1, (train_mAR / float(lo_train_dataset)) * 100., \n",
        "            epoch + 1, missed_train_images, lo_train_dataset\n",
        "        ))\n",
        "    \n",
        "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlfqIday1RLr",
        "outputId": "23f4b1a7-3950-402c-debd-bf7de01e5178"
      },
      "source": [
        "train_effdet(model, 1, eff_train_loader, eff_test_loader, 0.001, 1e-4, print_every = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Note: Train Accuracies are only run through one train image per batch\n",
            "Epoch 1/1 | Batch Number: 20 | LR: 0.00099 | Train_loss: 3623.97 | Test_loss: 367.30 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 70\n",
            "Epoch 1/1 | Batch Number: 40 | LR: 0.00098 | Train_loss: 69.74 | Test_loss: 359.09 | Test mAP: 0.23% | Test mAR: 0.47% | Missed Test Images: 6\n",
            "Epoch 1/1 | Batch Number: 60 | LR: 0.00095 | Train_loss: 69.72 | Test_loss: 359.25 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 22\n",
            "Epoch 1/1 | Batch Number: 80 | LR: 0.00091 | Train_loss: 70.75 | Test_loss: 367.56 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 100 | LR: 0.00087 | Train_loss: 67.79 | Test_loss: 375.18 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 120 | LR: 0.00082 | Train_loss: 67.74 | Test_loss: 377.71 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 140 | LR: 0.00075 | Train_loss: 69.27 | Test_loss: 362.36 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 160 | LR: 0.00069 | Train_loss: 69.03 | Test_loss: 361.96 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 180 | LR: 0.00062 | Train_loss: 67.36 | Test_loss: 357.59 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 200 | LR: 0.00054 | Train_loss: 67.50 | Test_loss: 356.67 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 220 | LR: 0.00047 | Train_loss: 66.42 | Test_loss: 363.37 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 240 | LR: 0.00040 | Train_loss: 65.39 | Test_loss: 353.97 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 260 | LR: 0.00033 | Train_loss: 66.01 | Test_loss: 354.42 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 280 | LR: 0.00026 | Train_loss: 66.63 | Test_loss: 354.32 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 300 | LR: 0.00020 | Train_loss: 65.47 | Test_loss: 354.11 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 320 | LR: 0.00014 | Train_loss: 65.44 | Test_loss: 351.63 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 340 | LR: 0.00009 | Train_loss: 65.43 | Test_loss: 353.63 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 360 | LR: 0.00006 | Train_loss: 65.22 | Test_loss: 351.27 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 380 | LR: 0.00003 | Train_loss: 66.03 | Test_loss: 353.22 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 400 | LR: 0.00001 | Train_loss: 64.94 | Test_loss: 352.83 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "Epoch 1/1 | Batch Number: 420 | LR: 0.00000 | Train_loss: 64.29 | Test_loss: 352.90 | Test mAP: 0.00% | Test mAR: 0.00% | Missed Test Images: 107\n",
            "\n",
            " Epoch 1 Final Train mAP: 0.68% | Epoch 1 Final Train mAR: 2.43% | Epoch 1 Final Missed Train Images: 368 out of 424 images \n",
            "\n",
            "Time for Total Training 239.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPmuew0CnX92"
      },
      "source": [
        "# The Mobile Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbDtIsBs-OWD"
      },
      "source": [
        "backbone = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
        "backbone.roi_heads.box_predictor.cls_score.out_features = 6\n",
        "backbone.roi_heads.box_predictor.bbox_pred.out_features = 24\n",
        "# backbone.roi_heads.box_predictor.cls_score.out_features = 3\n",
        "# backbone.roi_heads.box_predictor.bbox_pred.out_features = 12\n"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPCVMZBY_GaP",
        "outputId": "92a6ebba-be7e-417d-c799-99baed4270e6"
      },
      "source": [
        "another_one_1 = train(backbone, 5, train_loader, test_loader, noise_loader, 0.001, weight_decay = 1e-4, print_every = 80)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "Device: cuda\n",
            "Optimizer: SAM (\n",
            "Parameter Group 0\n",
            "    N_sma_threshhold: 5\n",
            "    alpha: 0.5\n",
            "    betas: (0.95, 0.999)\n",
            "    eps: 1e-05\n",
            "    initial_lr: 0.001\n",
            "    k: 6\n",
            "    lr: 0.001\n",
            "    rho: 0.05\n",
            "    step_counter: 0\n",
            "    weight_decay: 0.0001\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5 | Batch Number: 80 | LR: 0.00099 | Train_loss: 106.89 | Test_loss: 62.96 | Test mAP: 43.39% | Missed Test Images: 0 | Seperate Noise Loader: 5 / 100\n",
            "Epoch 1/5 | Batch Number: 160 | LR: 0.00095 | Train_loss: 66.04 | Test_loss: 51.57 | Test mAP: 41.02% | Missed Test Images: 0 | Seperate Noise Loader: 3 / 100\n",
            "\n",
            " Epoch 1 Final Train mAP: 29.55% | Epoch 1 Final Missed Train Images: 1 out of 456 images \n",
            "\n",
            "Epoch 2/5 | Batch Number: 80 | LR: 0.00083 | Train_loss: 54.52 | Test_loss: 58.23 | Test mAP: 45.46% | Missed Test Images: 1 | Seperate Noise Loader: 8 / 100\n",
            "Epoch 2/5 | Batch Number: 160 | LR: 0.00074 | Train_loss: 54.63 | Test_loss: 65.66 | Test mAP: 45.21% | Missed Test Images: 2 | Seperate Noise Loader: 19 / 100\n",
            "\n",
            " Epoch 2 Final Train mAP: 33.25% | Epoch 2 Final Missed Train Images: 4 out of 456 images \n",
            "\n",
            "Epoch 3/5 | Batch Number: 80 | LR: 0.00055 | Train_loss: 59.18 | Test_loss: 57.74 | Test mAP: 29.91% | Missed Test Images: 1 | Seperate Noise Loader: 28 / 100\n",
            "Epoch 3/5 | Batch Number: 160 | LR: 0.00044 | Train_loss: 57.17 | Test_loss: 50.26 | Test mAP: 32.64% | Missed Test Images: 1 | Seperate Noise Loader: 27 / 100\n",
            "\n",
            " Epoch 3 Final Train mAP: 33.48% | Epoch 3 Final Missed Train Images: 7 out of 456 images \n",
            "\n",
            "Epoch 4/5 | Batch Number: 80 | LR: 0.00025 | Train_loss: 49.01 | Test_loss: 85.06 | Test mAP: 52.32% | Missed Test Images: 5 | Seperate Noise Loader: 60 / 100\n",
            "Epoch 4/5 | Batch Number: 160 | LR: 0.00016 | Train_loss: 59.35 | Test_loss: 52.93 | Test mAP: 41.71% | Missed Test Images: 2 | Seperate Noise Loader: 47 / 100\n",
            "\n",
            " Epoch 4 Final Train mAP: 40.42% | Epoch 4 Final Missed Train Images: 19 out of 456 images \n",
            "\n",
            "Epoch 5/5 | Batch Number: 80 | LR: 0.00004 | Train_loss: 56.69 | Test_loss: 76.69 | Test mAP: 46.52% | Missed Test Images: 3 | Seperate Noise Loader: 53 / 100\n",
            "Epoch 5/5 | Batch Number: 160 | LR: 0.00001 | Train_loss: 53.90 | Test_loss: 77.58 | Test mAP: 45.39% | Missed Test Images: 4 | Seperate Noise Loader: 59 / 100\n",
            "\n",
            " Epoch 5 Final Train mAP: 45.58% | Epoch 5 Final Missed Train Images: 20 out of 456 images \n",
            "\n",
            "Time for Total Training 214.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjzRmGEPmjjF",
        "outputId": "2f32c1c8-573b-4684-b150-bf1c74948b83"
      },
      "source": [
        "another_one = train(backbone, 10, train_loader, test_loader, 0.001, weight_decay = 1e-4, print_every = 80)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "Device: cuda\n",
            "Optimizer: SAM (\n",
            "Parameter Group 0\n",
            "    N_sma_threshhold: 5\n",
            "    alpha: 0.5\n",
            "    betas: (0.95, 0.999)\n",
            "    eps: 1e-05\n",
            "    initial_lr: 0.001\n",
            "    k: 6\n",
            "    lr: 0.001\n",
            "    rho: 0.05\n",
            "    step_counter: 0\n",
            "    weight_decay: 0.0001\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Batch Number: 80 | LR: 0.00100 | Train_loss: 109.40 | Test_loss: 50.10 | Test mAP: 34.56% | Test mAR: nan% | Missed Test Images: 0\n",
            "Epoch 1/10 | Batch Number: 160 | LR: 0.00099 | Train_loss: 60.02 | Test_loss: 55.98 | Test mAP: 37.12% | Test mAR: nan% | Missed Test Images: 0\n",
            "\n",
            " Epoch 1 Final Train mAP: 30.74% | Epoch 1 Final Train mAR: nan% | Epoch 1 Final Missed Train Images: 0 out of 456 images \n",
            "\n",
            "Epoch 2/10 | Batch Number: 80 | LR: 0.00096 | Train_loss: 58.38 | Test_loss: 57.53 | Test mAP: 60.33% | Test mAR: nan% | Missed Test Images: 1\n",
            "Epoch 2/10 | Batch Number: 160 | LR: 0.00093 | Train_loss: 63.52 | Test_loss: 53.23 | Test mAP: 34.23% | Test mAR: nan% | Missed Test Images: 1\n",
            "\n",
            " Epoch 2 Final Train mAP: 31.06% | Epoch 2 Final Train mAR: nan% | Epoch 2 Final Missed Train Images: 6 out of 456 images \n",
            "\n",
            "Epoch 3/10 | Batch Number: 80 | LR: 0.00087 | Train_loss: 59.26 | Test_loss: 83.11 | Test mAP: 47.73% | Test mAR: nan% | Missed Test Images: 3\n",
            "Epoch 3/10 | Batch Number: 160 | LR: 0.00083 | Train_loss: 61.76 | Test_loss: 55.83 | Test mAP: 27.57% | Test mAR: nan% | Missed Test Images: 1\n",
            "\n",
            " Epoch 3 Final Train mAP: 30.96% | Epoch 3 Final Train mAR: nan% | Epoch 3 Final Missed Train Images: 6 out of 456 images \n",
            "\n",
            "Epoch 4/10 | Batch Number: 80 | LR: 0.00075 | Train_loss: 58.68 | Test_loss: 79.41 | Test mAP: 38.63% | Test mAR: nan% | Missed Test Images: 4\n",
            "Epoch 4/10 | Batch Number: 160 | LR: 0.00070 | Train_loss: 61.69 | Test_loss: 66.05 | Test mAP: 38.82% | Test mAR: nan% | Missed Test Images: 3\n",
            "\n",
            " Epoch 4 Final Train mAP: 33.09% | Epoch 4 Final Train mAR: nan% | Epoch 4 Final Missed Train Images: 8 out of 456 images \n",
            "\n",
            "Epoch 5/10 | Batch Number: 80 | LR: 0.00060 | Train_loss: 58.89 | Test_loss: 80.11 | Test mAP: 38.94% | Test mAR: nan% | Missed Test Images: 1\n",
            "Epoch 5/10 | Batch Number: 160 | LR: 0.00055 | Train_loss: 56.70 | Test_loss: 78.22 | Test mAP: 35.02% | Test mAR: nan% | Missed Test Images: 1\n",
            "\n",
            " Epoch 5 Final Train mAP: 34.09% | Epoch 5 Final Train mAR: nan% | Epoch 5 Final Missed Train Images: 7 out of 456 images \n",
            "\n",
            "Epoch 6/10 | Batch Number: 80 | LR: 0.00044 | Train_loss: 52.62 | Test_loss: 86.22 | Test mAP: 43.91% | Test mAR: nan% | Missed Test Images: 2\n",
            "Epoch 6/10 | Batch Number: 160 | LR: 0.00039 | Train_loss: 59.55 | Test_loss: 93.01 | Test mAP: 46.96% | Test mAR: nan% | Missed Test Images: 3\n",
            "\n",
            " Epoch 6 Final Train mAP: 37.65% | Epoch 6 Final Train mAR: nan% | Epoch 6 Final Missed Train Images: 20 out of 456 images \n",
            "\n",
            "Epoch 7/10 | Batch Number: 80 | LR: 0.00029 | Train_loss: 54.05 | Test_loss: 99.96 | Test mAP: 39.45% | Test mAR: nan% | Missed Test Images: 4\n",
            "Epoch 7/10 | Batch Number: 160 | LR: 0.00025 | Train_loss: 58.93 | Test_loss: 79.80 | Test mAP: 34.77% | Test mAR: nan% | Missed Test Images: 1\n",
            "\n",
            " Epoch 7 Final Train mAP: 38.81% | Epoch 7 Final Train mAR: nan% | Epoch 7 Final Missed Train Images: 18 out of 456 images \n",
            "\n",
            "Epoch 8/10 | Batch Number: 80 | LR: 0.00016 | Train_loss: 58.33 | Test_loss: 90.27 | Test mAP: 38.50% | Test mAR: nan% | Missed Test Images: 3\n",
            "Epoch 8/10 | Batch Number: 160 | LR: 0.00012 | Train_loss: 52.78 | Test_loss: 92.37 | Test mAP: 45.57% | Test mAR: nan% | Missed Test Images: 3\n",
            "\n",
            " Epoch 8 Final Train mAP: 43.94% | Epoch 8 Final Train mAR: nan% | Epoch 8 Final Missed Train Images: 24 out of 456 images \n",
            "\n",
            "Epoch 9/10 | Batch Number: 80 | LR: 0.00007 | Train_loss: 52.34 | Test_loss: 99.14 | Test mAP: 48.14% | Test mAR: nan% | Missed Test Images: 4\n",
            "Epoch 9/10 | Batch Number: 160 | LR: 0.00004 | Train_loss: 59.78 | Test_loss: 97.68 | Test mAP: 42.97% | Test mAR: nan% | Missed Test Images: 4\n",
            "\n",
            " Epoch 9 Final Train mAP: 47.44% | Epoch 9 Final Train mAR: nan% | Epoch 9 Final Missed Train Images: 29 out of 456 images \n",
            "\n",
            "Epoch 10/10 | Batch Number: 80 | LR: 0.00001 | Train_loss: 53.61 | Test_loss: 105.94 | Test mAP: 44.46% | Test mAR: nan% | Missed Test Images: 4\n",
            "Epoch 10/10 | Batch Number: 160 | LR: 0.00000 | Train_loss: 53.82 | Test_loss: 105.05 | Test mAP: 45.50% | Test mAR: nan% | Missed Test Images: 4\n",
            "\n",
            " Epoch 10 Final Train mAP: 51.20% | Epoch 10 Final Train mAR: nan% | Epoch 10 Final Missed Train Images: 27 out of 456 images \n",
            "\n",
            "Time for Total Training 381.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-cknP0_uy0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916917ab-36c0-4f8a-fd3c-0fcfe2fa1754"
      },
      "source": [
        "# https://github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py#L48\n",
        "def intersect(box_a, box_b):\n",
        "\n",
        "    A = box_a.size(0)\n",
        "    B = box_b.size(0)\n",
        "    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n",
        "    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n",
        "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
        "    return inter[:, :, 0] * inter[:, :, 1]\n",
        "\n",
        "def jaccard_iou(box_a, box_b):\n",
        "\n",
        "    inter = intersect(box_a, box_b)\n",
        "    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n",
        "              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n",
        "    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n",
        "              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n",
        "    union = area_a + area_b - inter\n",
        "    return inter / union  # [A,B]\n",
        "\n",
        "def calculate_iou_on_label(results, len_of_results, iou_thresh, device):\n",
        "  for current_index, _ in enumerate(results[\"boxes\"]):\n",
        "    if current_index >= len_of_results:\n",
        "      break\n",
        "\n",
        "    current_index_iou = jaccard_iou(results[\"boxes\"][current_index].view(1, -1).to(device),\n",
        "                                    results[\"boxes\"].to(device))\n",
        "    \n",
        "    mask = (current_index_iou > iou_thresh) & (current_index_iou != 1)\n",
        "    mask = mask.squeeze()\n",
        "    for key in results:\n",
        "      results[key] = results[key][~mask]\n",
        "\n",
        "    len_of_results -= sum(mask)\n",
        "  \n",
        "  return results\n",
        "\n",
        "def get_labels_categ(classes, want):\n",
        "  fruit_index_list, bad_spot_index_list = list(), list()\n",
        "  for ii, name in enumerate(classes):\n",
        "    if re.search(\"Spot\", name):\n",
        "      bad_spot_index_list.append(ii)\n",
        "    elif re.search(\"Placeholder\", name):\n",
        "      continue\n",
        "    else:\n",
        "      fruit_index_list.append(ii)\n",
        "  \n",
        "  if want == \"fruit\":\n",
        "    return fruit_index_list\n",
        "  elif want == \"bad_spot\":\n",
        "    return bad_spot_index_list\n",
        "  else:\n",
        "    raise ValueError(\"want Type not applicable [fruit or bad_spot only]\")\n",
        "\n",
        "print(classes)\n",
        "get_labels_categ(classes, \"bad_spot\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Placeholder', 'Apples', 'Strawberry', 'Tomato', 'Apple_Bad_Spot', 'Strawberry_Bad_Spot', 'Tomato_Bad_Spot']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFhjlggXlAx7"
      },
      "source": [
        "def infer_image(image_file_path, trained_model, distance_thresh, iou_thresh, webcam = False, show_image = True):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  #Just load it up as PIL. Avoid using cv2 because do not need albumentations\n",
        "  if not webcam:\n",
        "    torch_image = F.to_tensor(Image.open(image_file_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "    trained_model.to(device)\n",
        "    trained_model.eval()\n",
        "    print(\"Image Size: {}\".format(torch_image.size()))\n",
        "\n",
        "    start_time = time.time()\n",
        "    results = trained_model(torch_image)\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"Time of Inference {:0.2f}\".format(end_time))\n",
        "  else:\n",
        "\n",
        "    torch_image = F.to_tensor(image_file_path).unsqueeze(1).to(device)\n",
        "\n",
        "    results = trained_model(torch_image)\n",
        "\n",
        "  valid_box_count = 0\n",
        "  for ii, score in enumerate(results[0][\"scores\"]):\n",
        "    if score < distance_thresh:\n",
        "      low_index_start = ii\n",
        "      break\n",
        "    else:\n",
        "      valid_box_count += 1\n",
        "\n",
        "  if valid_box_count == len(results[0][\"scores\"]):\n",
        "    low_index_start = len(results[0][\"scores\"])\n",
        "  \n",
        "  for key in results[0]:\n",
        "    results[0][key] = results[0][key][:low_index_start]\n",
        "  \n",
        "  #This is where I place the order of the list\n",
        "  fruit_spot_iou_thresh, bad_spot_iou_thresh = iou_thresh\n",
        "\n",
        "  #Update when I get more data of fruits and when running for script beware of classes.\n",
        "  bad_spot_index = [ii for ii, label in enumerate(results[0][\"labels\"]) if label in get_labels_categ(classes, \"bad_spot\")]\n",
        "  fruit_index = [ii for ii, _ in enumerate(results[0][\"labels\"]) if ii not in bad_spot_index]\n",
        "\n",
        "  bad_spot_results, fruit_results = dict(), dict()\n",
        "\n",
        "  for key in results[0]:\n",
        "    bad_spot_results[key], fruit_results[key] = results[0][key][[bad_spot_index]], results[0][key][[fruit_index]]\n",
        "\n",
        "  assert len(bad_spot_results[\"boxes\"]) == len(bad_spot_results[\"scores\"]) == len(bad_spot_results[\"labels\"])\n",
        "  assert len(fruit_results[\"boxes\"]) == len(fruit_results[\"scores\"]) == len(fruit_results[\"labels\"])\n",
        "\n",
        "  len_of_bad_spots, len_of_fruit = len(bad_spot_results[\"boxes\"]), len(fruit_results[\"boxes\"])\n",
        "\n",
        "  if len_of_bad_spots > 1:\n",
        "    bad_spot_results = calculate_iou_on_label(bad_spot_results, len_of_bad_spots, bad_spot_iou_thresh, device)\n",
        "  if len_of_fruit > 1:\n",
        "    fruit_results = calculate_iou_on_label(fruit_results, len_of_fruit, fruit_spot_iou_thresh, device)\n",
        "  \n",
        "  for key in results[0]: \n",
        "    if (key == \"boxes\"):\n",
        "      results[0][\"boxes\"] = torch.cat((fruit_results[\"boxes\"], bad_spot_results[\"boxes\"]), axis = 0)\n",
        "    else:\n",
        "      results[0][key] = torch.cat((fruit_results[key], bad_spot_results[key]), dim = 0)\n",
        "\n",
        "  if show_image:\n",
        "    if device == torch.device(\"cuda\"):\n",
        "      torch_image = torch_image.cpu() \n",
        "    written_image = cv2.cvtColor(draw_boxes(results[0][\"boxes\"], results[0][\"labels\"], torch_image.squeeze(), infer = True, put_text= True), cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(written_image)\n",
        "  \n",
        "  return results"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ab85jWlu5L7"
      },
      "source": [
        "results = infer_image(\"/content/tomatpred.jpg\", another_one, 0.2, [0.3, 0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZd4nVDuiu4M"
      },
      "source": [
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      /* try changing the capture canvas and see what happens*/\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T45EScTjJ5e"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def js_reply_to_image(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    image_array = np.array(image_PIL)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def drawing_array_to_bytes(drawing_array):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          drawing_array: image RGBA size 512 x 512 \n",
        "                              contain bounding box and text from yolo prediction, \n",
        "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
        "                              else channel A value = 0\n",
        "\n",
        "    output: \n",
        "          drawing_bytes: string, encoded from drawing_array\n",
        "    \"\"\"\n",
        "\n",
        "    drawing_PIL = Image.fromarray(drawing_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    drawing_PIL.save(iobuf, format='png')\n",
        "    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "    return drawing_bytes"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FSrjfHjgX4q"
      },
      "source": [
        "data_transforms = get_transforms(mode = \"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "j0WidBmGlktM",
        "outputId": "6e291470-abb3-45b9-8be7-c90bf01e15e3"
      },
      "source": [
        "start_input()\n",
        "label_html = 'Capturing...'\n",
        "img_data = ''\n",
        "count = 0 \n",
        "\n",
        "color=None\n",
        "label=None\n",
        "line_thickness=None\n",
        "another_one.to(device).eval();\n",
        "while True:\n",
        "    js_reply = take_photo(label_html, img_data)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    image = js_reply_to_image(js_reply)\n",
        "    prediciton = infer_image(image, another_one, 0.03, [0.3, 0.1], webcam= True, show_image = False)\n",
        "\n",
        "    drawing_array = np.zeros([512,512,4], dtype=np.uint8)\n",
        "\n",
        "    for x in prediciton[0]['boxes']:\n",
        "\n",
        "      tl = line_thickness or round(0.002 * (drawing_array.shape[0] + drawing_array.shape[1]) / 2) + 1  # line/font thickness\n",
        "      color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "      c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "      cv2.rectangle(drawing_array, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "      if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(drawing_array, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(drawing_array, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "    drawing_array[:,:,3] = (drawing_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "\n",
        "    drawing_PIL = Image.fromarray(drawing_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    drawing_PIL.save(iobuf, format='png')\n",
        "    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "    img_data = drawing_bytes"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      /* try changing the capture canvas and see what happens*/\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}